import os
import sys
import json
import requests
from datetime import datetime, date, timedelta

from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.sensors.python import PythonSensor
from airflow.operators.python_operator import PythonOperator
from airflow.contrib.operators.ssh_operator import SSHOperator

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –∏–∑–º–µ–Ω–∏—Ç—Å—è
with open('/tmp/zhalybin/yaApi_logs/json_hits_constant.json', 'r', encoding="utf-8") as jsonFile1:
    constantJsonData = json.load(jsonFile1)

# –î–∞—Ç—ã –¥–ª—è –≤—ã–±–æ—Ä–æ—á–Ω–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ –≤ json,
# —á—Ç–æ–± –ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª –Ω–∞ —Ö–æ—Å—Ç–µ –∞ –Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ 
with open('/tmp/zhalybin/yaApi_logs/json_hits_select_date.json', 'r', encoding="utf-8") as jsonFile2:
    selectDateJsonData = json.load(jsonFile2)

# –î–∞—Ç—ã –¥–ª—è –≤—ã–±–æ—Ä–æ—á–Ω–æ–π –≤—ã–≥—Ä—É–∑–∫–∏
start_date_v = selectDateJsonData['YaApiHitsDate']['startDate']
end_date_v = selectDateJsonData['YaApiHitsDate']['endDate']

# –ü—Ä–∞–º–µ—Ç—Ä—ã –≤—ã–≥—Ä—É–∑–∫–∏ 
col_tab_Basic = constantJsonData['YaApiHitsConstant']['col_tab_Basic']
col_tab_TrafficSource = constantJsonData['YaApiHitsConstant']['col_tab_TrafficSource']
col_tab_Ecommerce_EventParams_EventType = constantJsonData['YaApiHitsConstant']['col_tab_Ecommerce_EventParams_EventType']
col_tab_Device = constantJsonData['YaApiHitsConstant']['col_tab_Device']

counter_id_v = constantJsonData['YaApiHitsConstant']['counter_id']
API_token_v = constantJsonData['YaApiHitsConstant']['API_token']
headers_v = {'Authorization': f"OAuth {API_token_v}", 'Accept-Encoding': 'gzip'}

# BASH –∫–æ–º–∞–Ω–¥—ã –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ–ª–∫–∞—é—Ç —Å–∫—Ä–∏–ø—Ç—ã –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ 08 —Ö–æ—Å—Ç–∞  
bash_clear_tmp = '/usr/bin/python3 /home/bdataadmin/airflow/test_script/clear_logs_folder.py'
bash_clear_hdfs = '/usr/bin/bash /home/bdataadmin/airflow/test_script/—Åheck_hdfs_txt.sh '

bash_rm_4dir_hdfs = '/usr/bin/bash /home/bdataadmin/airflow/test_script/remove_4dir_hdfs.sh '

bash_command_extract_partsize = '/usr/bin/python3 /home/bdataadmin/airflow/test_script/extract_partsize.py'
bash_download_txt = '/usr/bin/python3 /home/bdataadmin/airflow/test_script/dowload_parts.py'
bash_merge_txt = '/usr/bin/python3 /home/bdataadmin/airflow/test_script/merge_txt.py'
bash_hdfs_put_bigTxt = '/usr/bin/bash hdfs dfs -put /home/bdataadmin/airflow/txt_big/final_txt.txt /user/azhalybin/airflow/test/txt '

bash_start_pySpark_basic_orc = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_basic_orc.sh '
bash_start_pySpark_trafficSource_orc = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_trafficSource_orc.sh '
bash_start_pySpark_3E_orc = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_3E_orc.sh '
bash_start_pySpark_Device_orc = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_device_orc.sh '
bash_start_pySpark_join = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_join.sh '

# –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è —Ä–∞–±–æ—Ç—ã DAG-–∞
# –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ airflow —Ö—Å—Ç–∞  
path_request_id_v = '/tmp/zhalybin/yaApi_logs/request_id.txt'
path_faild_v = '/tmp/zhalybin/yaApi_logs/hits_faild.txt'


def read_request_id(path_request_id):
    """
    –§—É–Ω–∫—Ü–∏—è –Ω—É–∂–Ω–∞ —á—Ç–æ–± —á–∏—Ç–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π request_id,
    –æ–Ω–∞ —á–∏—Ç–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ —Ñ–∞–π–ª–µ –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è
    """
    with open(path_request_id, "r") as f:
        request_id = f.read()
    return request_id

# –ó–∞–ø–∏—Å—ã–≤–µ–º –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏–Ω–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤—ã–≥—Ä—É–∑–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
# –∏–∑ —Ñ–∞–π–ª–∞ –Ω–∞ —Ö–æ—Å—Ç–µ airflow - –ø–æ—Ç–æ–º—É —á—Ç–æ –º–æ–≥—É –∏ xcom –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç
request_id_v = read_request_id(path_request_id=path_request_id_v)
# –î—É–±–ª–∏—Ä—É–µ–º –∏–Ω–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤—ã–≥—Ä—É–∑–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ 08 —Ö–æ—Å—Ç–µ
bash_command_request_id = f'echo "{request_id_v}" > /home/bdataadmin/airflow/logs/request_id.txt'


def ocenka_vozmozhnisti_sozd_zaprosa(counter_id, API_token, headers, start_date, end_date, col_tab):
    """
    –û—Ü–µ–Ω–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –Ø–ú,
    —Ñ—É–Ω–∫—Ü–∏—è —à–ª–µ—Ç –∑–∞–ø—Ä–æ—Å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –≤—ã–≥—Ä—É–∑–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç
    –∏ –º—ã –æ–∂–∏–¥–∞–µ–º –æ—Ç–≤–µ—Ç r.json()['log_request_evaluation']['possible'] == True
    """
    get_ocenka = f"https://api-metrika.yandex.net/management/v1/counter/{counter_id}/logrequests/evaluate"

    params_ocenka = {
        'date1': start_date,
        'date2': end_date,
        'fields': col_tab,
        'source': 'hits'  # hits visits
    }

    r = requests.get(get_ocenka, params=params_ocenka, headers=headers)

    if r.status_code == 200:
        if r.json()['log_request_evaluation']['possible'] == True:
            print('–í—ã–≥—Ä—É–∑–∫–∞ –≤–æ–∑–º–æ–∂–Ω–∞')
        elif r.json()['log_request_evaluation']['possible'] == False:
            print('YaApi –æ—Ç–≤–µ—Ç–∏–ª —á—Ç–æ –≤—ã–≥—Ä—É–∑–∫–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞ ' + str(r.status_code))
            return False
        else:
            print('–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫' + str(r.status_code))
            return False
    else:
        sys.exit('–ó–∞–ø—Ä–æ—Å —É–ø–∞–ª: ' + str(r.status_code))
        return False


def sozd_zaprosa_logov(counter_id, API_token, headers, start_date, end_date, col_tab, path_request_id):
    """
    –ò—Å—Ö–æ–¥—è –∏–∑ –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
    –º—ã –æ—Ç–ø—Ä–ø–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≥—Ä—É–∑–∫–∏. 
    –ü–æ—Ö–æ–∂–∏–π —Å–∫—Ä–∏–ø—Ç –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ 08 —Ö–æ—Å—Ç–∞ —Å–∫–∞—á–∏–≤–∞–µ—Ç –∏
    –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ —Ñ–∞–π–ª –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø–∞—Ä –∑–Ω—á–µ–Ω–∏–π:
    –Ω–æ–º–µ—Ä —á–∞—Å—Ç–∏ –≤—ã–≥—Ä—É–∑–∫–∏ (parts) –∏ —Ä–∞–∑–º–µ—Ä —ç—Ç–æ–π —á–∞—Å—Ç–∏ (partSizes) 
    """
    post_sozdanie_zaprosa_logov = f"https://api-metrika.yandex.net/management/v1/counter/{counter_id}/logrequests"

    params_sozdanie_zaprosa_logov = {
        'date1': start_date,
        'date2': end_date,
        'fields': col_tab,
        'source': 'hits'  # hits visits
    }

    r = requests.post(post_sozdanie_zaprosa_logov, params=params_sozdanie_zaprosa_logov, headers=headers)

    if os.path.exists(path_request_id) == True:
        os.remove(path_request_id)

    if r.status_code == 200:
        if r.json()['log_request']['status'] == 'created':
            print('–ó–∞–ø—Ä–æ—Å —Å–æ–∑–¥–∞—ë—Ç—Å—è')
            # print(r.json()['log_request']['request_id'])
            with open(path_request_id, 'w', encoding='utf-8') as f:
                f.write(str(r.json()['log_request']['request_id']))
        else:
            sys.exit('–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫' + str(r.status_code))
            return False
    else:
        sys.exit('–ó–∞–ø—Ä–æ—Å —É–ø–∞–ª: ' + str(r.status_code))
        return False


def get_status(counter_id, API_token, headers, request_id):
    """
    –ü–æ—Å–ª–µ —Å–æ–∑–¥–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –Ø–ú, —Å–∞–º–æ–º—É –Ø–ú 
    —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—Ä–µ–º—è –Ω–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≥—Ä—É–∑–∫–∏
    –∏ —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º
    –≥–æ—Ç–æ–≤ –ª–∏ –∫ –≤—ã–≥—Ä—É–∑–∫–µ –Ω–∞—à –∑–∞–ø—Ä–æ—Å
    """

    get_status = f"https://api-metrika.yandex.net/management/v1/counter/{counter_id}/logrequest/{request_id}"

    r = requests.get(get_status, headers=headers)

    if r.status_code == 200:
        if r.json()['log_request']['status'] == 'processed':
            print('–£—Å–ø–µ—Ö')
            return True
        elif r.json()['log_request']['status'] == 'created':
            print('–ù—É–∂–Ω–æ –∂–¥–∞—Ç—å, –∑–∞–ø—Ä–æ—Å –≤ —Å—Ç–∞—Ç—É—Å–µ created –∏ —É–∂–µ –≥–æ—Ç–æ–≤–∏—Ç—Å—è –∏–ª–∏ –≤ –æ—á–µ—Ä–µ–¥–∏ –Ω–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ')
            return False
        else:
            sys.exit('–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫' + str(r.status_code))
            return False
    else:
        sys.exit('–ó–∞–ø—Ä–æ—Å —É–ø–∞–ª: ' + str(r.status_code))
        return False


def clear_YaApi_query(counter_id, API_token, headers, request_id):
    """
    –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π –∑–∞–ø—Ä–æ—Å–∞ 
    –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Ö –Ω–∞ –ø–æ–ª–Ω–æ—Ç—É (–Ω–∞ —Å—Ç—Ä–æ–Ω–µ 08 —Ö–æ—Å—Ç–∞)
    –º—ã –æ—á–∏—â–∞–µ–º –Ω–∞—à–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (–≤ –∫–æ—Ç–æ—Ä–æ–º 10 –ì–±
    –≤ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–π –≤–µ—Ä—Å–∏–∏) –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –≤—ã–≥—Ä—É–∑–æ–∫   
    """
    post_clean = f"https://api-metrika.yandex.net/management/v1/counter/{counter_id}/logrequest/{request_id}/clean"
    r = requests.post(post_clean, headers=headers)
    if r.status_code == 200:
        if r.json()['log_request']['status'] == 'cleaned_by_user':
            print('–î–∞–Ω–Ω—ã–µ –Ø–Ω–¥–µ–∫—Å –º–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω—ã –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –Ø–Ω–¥–µ–∫—Å–∞')
        else:
            sys.exit('–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫' + str(r.status_code))
            return False
    else:
        sys.exit('–ó–∞–ø—Ä–æ—Å —É–ø–∞–ª: ' + str(r.status_code))
        return False


# DAG —É–ø–∞–ª üõë
# DAG –æ—Ç—Ä–∞–±–æ—Ç–∞–ª —É—Å–ø–µ—à–Ω–æ ‚úÖ
def tlgrm(message):
    """
    –§—É–Ω–∫—Ü–∏—è —á–µ—Ä–µ–∑ —Ç–µ–ª–µ–≥—Ä–∞–º–º –±–æ—Ç —à–ª–µ—Ç –≤ —Ç–µ–ª–µ–≥—Ä–∞–º–º –±–µ—Å–µ–¥—É
    –æ—Ç—á—ë—Ç—ã –æ–± —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –∏–ª–∏ –Ω–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è DAG-–∞.
    –ë–µ—Å–µ–¥–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è: AFLT_BigDataReports
    """
    token = "7437864886:AAGbHErZlCVqycGfYhkrB14iYevybpqErjc"
    url = "https://api.telegram.org/bot"
    channel_id = "-1002335777312"
    url += token
    method = url + "/sendMessage"
    #    proxy = {'https': '192.168.41.118:1080'}
    #    proxy = {'https': 'http://192.168.41.118:1080'}

    try:
        r = requests.post(method,
                          data={
                              "chat_id": channel_id,
                              "text": message},
                          #                          proxies=proxy,
                          timeout=30)
        print(r.json())
    except requests.exceptions.ConnectionError:
        print("–ò—Å–∫–ª_1")
        return False


def logging_faild(text, path_faild):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª —Ñ–∞–∫—Ç –Ω–µ—É—Å–ø–µ—Ö–∞
    –∏ –∏–Ω–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤—ã–≥—Ä—É–∑–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
    –¥–ª—è —á—Ç–æ–± –æ—á–∏—Ç–∏—Ç—å –µ–≥–æ –≤—Ä—É—á–Ω—É—é, –µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è
    """
    with open(path_faild, 'a', encoding='utf-8') as f:
        f.write(text + '\n')


default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 8, 25),
    'retries': 0
}

# –í DAG-–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –ª–æ–≥–∏–∫–∞ –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–π –≤—ã–≥—Ä—É–∑–∫–∞ –¥–µ–ª–∏—Ç—Å—è –Ω–∞ 4 —á–∞—Å—Ç–∏
# –∏ join-—Ç—Å—è –Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —ç—Ç–∞–ø–µ —Å –æ—Ç—Ä–∞–≤–∫–æ–π —Å–æ–æ–±—â–µ–Ω–∏–π —Ç–µ–ª–µ–≥—Ä–∞–º —Ä–µ–ø–æ—Ä—Ç–µ—Ä.
# –ï—Å–ª–∏ –Ω–∞ –∫–∞–∫–æ–º-—Ç–æ —É–∑–ª–µ DAG-–∞ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ - —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –≤—ã–≥—Ä—É–∑–∫–∞ –Ω–µ—É—Å–ø–µ—à–Ω–∞
# –∏ –¥–ª—è –¥–∞–Ω–Ω–æ–π –¥–∞—Ç—ã –Ω—É–∂–Ω–æ –Ω–∞—á–∏–Ω–∞—Ç—å –≤—Å–µ —Å–Ω–∞—á–∞–ª–∞. 
# –î–ª—è –≤–∏–∑–∏—Ç–æ–≤ –∏ —Ö–∏—Ç–æ–≤ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –ø–∞—Ä—ã DAG-–æ–≤: 1)—Å –≤—ã–±–æ—Ä–æ–º –¥–∞—Ç—ã –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏
# 2) –∏ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –Ω–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ - –∫–æ—Ç—Ä—Ä—ã–π –ª—É—á—à–µ –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å.
with DAG(dag_id='BigData_YaApi_hits_date_selection',
         tags=["ETL –¥–ª—è —Ä–∞–∑–æ–≤—ã—Ö –≤—ã–≥—Ä—É–∑–æ–∫"],
         default_args=default_args,
         schedule_interval='@once',
         start_date=days_ago(1)
         ) as dag:

    task_clear_tmp_1 = SSHOperator(
        task_id='task_clear_tmp_1',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_1 = SSHOperator(
        task_id='task_clear_hdfs_1',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    task_rm_4dir_hdfs_1 = SSHOperator(
        task_id='task_rm_4dir_hdfs_1',
        ssh_conn_id="ssh_08",
        command=bash_rm_4dir_hdfs,
        dag=dag
    )

    ocenka_vozmozhnisti_sozd_zaprosa_1 = PythonOperator(
        task_id='ocenka_vozmozhnisti_sozd_zaprosa_1',
        python_callable=ocenka_vozmozhnisti_sozd_zaprosa,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Basic}
    )

    sozd_zaprosa_logov_1 = PythonOperator(
        task_id='sozd_zaprosa_logov_1',
        python_callable=sozd_zaprosa_logov,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Basic,
            'path_request_id': path_request_id_v}
    )

    get_status_1 = PythonSensor(
        task_id='get_status_1',
        python_callable=get_status,
        poke_interval=5 * 60,  # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç, –ß–µ—Ä–µ–∑ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è (5 * 60)
        timeout=12 * 60 * 60,  # –≤—Ä–µ–º—è –¥–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞–¥–µ–Ω–∏—è, 12 —á–∞—Å–æ–≤
        # retries=720,
        soft_fail=False,
        mode="reschedule",
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_save_request_id_1 = SSHOperator(
        task_id='task_save_request_id_1',
        ssh_conn_id="ssh_08",
        command=bash_command_request_id,
        dag=dag
    )

    task_extract_partsize_1 = SSHOperator(
        task_id='task_extract_partsize_1',
        ssh_conn_id="ssh_08",
        command=bash_command_extract_partsize,
        dag=dag
    )

    task_download_txt_1 = SSHOperator(
        task_id='task_download_txt_1',
        ssh_conn_id="ssh_08",
        command=bash_download_txt,
        dag=dag
    )

    task_merge_txt_1 = SSHOperator(
        task_id='task_merge_txt_1',
        ssh_conn_id="ssh_08",
        command=bash_merge_txt,
        dag=dag
    )

    clear_YaApi_query_1 = PythonOperator(
        task_id='clear_YaApi_query_1',
        python_callable=clear_YaApi_query,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_move_bigTxt_1 = SSHOperator(
        task_id='task_move_bigTxt_1',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_Basic_orc = SSHOperator(
        task_id='task_start_pySpark_Basic_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_basic_orc,
        dag=dag
    )

    task_clear_tmp_2 = SSHOperator(
        task_id='task_clear_tmp_2',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_2 = SSHOperator(
        task_id='task_clear_hdfs_2',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    ocenka_vozmozhnisti_sozd_zaprosa_2 = PythonOperator(
        task_id='ocenka_vozmozhnisti_sozd_zaprosa_2',
        python_callable=ocenka_vozmozhnisti_sozd_zaprosa,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_TrafficSource}
    )

    sozd_zaprosa_logov_2 = PythonOperator(
        task_id='sozd_zaprosa_logov_2',
        python_callable=sozd_zaprosa_logov,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_TrafficSource,
            'path_request_id': path_request_id_v}
    )

    get_status_2 = PythonSensor(
        task_id='get_status_2',
        python_callable=get_status,
        poke_interval=5 * 60,  # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç, –ß–µ—Ä–µ–∑ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è (5 * 60)
        timeout=12 * 60 * 60,  # –≤—Ä–µ–º—è –¥–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞–¥–µ–Ω–∏—è, 12 —á–∞—Å–æ–≤
        # retries=720,
        soft_fail=False,
        mode="reschedule",
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_save_request_id_2 = SSHOperator(
        task_id='task_save_request_id_2',
        ssh_conn_id="ssh_08",
        command=bash_command_request_id,
        dag=dag
    )

    task_extract_partsize_2 = SSHOperator(
        task_id='task_extract_partsize_2',
        ssh_conn_id="ssh_08",
        command=bash_command_extract_partsize,
        dag=dag
    )

    task_download_txt_2 = SSHOperator(
        task_id='task_download_txt_2',
        ssh_conn_id="ssh_08",
        command=bash_download_txt,
        dag=dag
    )

    task_merge_txt_2 = SSHOperator(
        task_id='task_merge_txt_2',
        ssh_conn_id="ssh_08",
        command=bash_merge_txt,
        dag=dag
    )

    clear_YaApi_query_2 = PythonOperator(
        task_id='clear_YaApi_query_2',
        python_callable=clear_YaApi_query,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_move_bigTxt_2 = SSHOperator(
        task_id='task_move_bigTxt_2',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_TrafficSource_orc = SSHOperator(
        task_id='task_start_pySpark_TrafficSource_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_trafficSource_orc,
        dag=dag
    )

    task_clear_tmp_3 = SSHOperator(
        task_id='task_clear_tmp_3',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_3 = SSHOperator(
        task_id='task_clear_hdfs_3',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    ocenka_vozmozhnisti_sozd_zaprosa_3 = PythonOperator(
        task_id='ocenka_vozmozhnisti_sozd_zaprosa_3',
        python_callable=ocenka_vozmozhnisti_sozd_zaprosa,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Ecommerce_EventParams_EventType}
    )

    sozd_zaprosa_logov_3 = PythonOperator(
        task_id='sozd_zaprosa_logov_3',
        python_callable=sozd_zaprosa_logov,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Ecommerce_EventParams_EventType,
            'path_request_id': path_request_id_v}
    )

    get_status_3 = PythonSensor(
        task_id='get_status_3',
        python_callable=get_status,
        poke_interval=5 * 60,  # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç, –ß–µ—Ä–µ–∑ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è (5 * 60)
        timeout=12 * 60 * 60,  # –≤—Ä–µ–º—è –¥–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞–¥–µ–Ω–∏—è, 12 —á–∞—Å–æ–≤
        # retries=720,
        soft_fail=False,
        mode="reschedule",
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_save_request_id_3 = SSHOperator(
        task_id='task_save_request_id_3',
        ssh_conn_id="ssh_08",
        command=bash_command_request_id,
        dag=dag
    )

    task_extract_partsize_3 = SSHOperator(
        task_id='task_extract_partsize_3',
        ssh_conn_id="ssh_08",
        command=bash_command_extract_partsize,
        dag=dag
    )

    task_download_txt_3 = SSHOperator(
        task_id='task_download_txt_3',
        ssh_conn_id="ssh_08",
        command=bash_download_txt,
        dag=dag
    )

    task_merge_txt_3 = SSHOperator(
        task_id='task_merge_txt_3',
        ssh_conn_id="ssh_08",
        command=bash_merge_txt,
        dag=dag
    )

    clear_YaApi_query_3 = PythonOperator(
        task_id='clear_YaApi_query_3',
        python_callable=clear_YaApi_query,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_move_bigTxt_3 = SSHOperator(
        task_id='task_move_bigTxt_3',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_3E_orc = SSHOperator(
        task_id='task_start_pySpark_3E_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_3E_orc,
        dag=dag
    )

    task_clear_tmp_4 = SSHOperator(
        task_id='task_clear_tmp_4',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_4 = SSHOperator(
        task_id='task_clear_hdfs_4',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    ocenka_vozmozhnisti_sozd_zaprosa_4 = PythonOperator(
        task_id='ocenka_vozmozhnisti_sozd_zaprosa_4',
        python_callable=ocenka_vozmozhnisti_sozd_zaprosa,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Device}
    )

    sozd_zaprosa_logov_4 = PythonOperator(
        task_id='sozd_zaprosa_logov_4',
        python_callable=sozd_zaprosa_logov,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Device,
            'path_request_id': path_request_id_v}
    )

    get_status_4 = PythonSensor(
        task_id='get_status_4',
        python_callable=get_status,
        poke_interval=5 * 60,  # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç, –ß–µ—Ä–µ–∑ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è (5 * 60)
        timeout=12 * 60 * 60,  # –≤—Ä–µ–º—è –¥–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞–¥–µ–Ω–∏—è, 12 —á–∞—Å–æ–≤
        # retries=720,
        soft_fail=False,
        mode="reschedule",
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_save_request_id_4 = SSHOperator(
        task_id='task_save_request_id_4',
        ssh_conn_id="ssh_08",
        command=bash_command_request_id,
        dag=dag
    )

    task_extract_partsize_4 = SSHOperator(
        task_id='task_extract_partsize_4',
        ssh_conn_id="ssh_08",
        command=bash_command_extract_partsize,
        dag=dag
    )

    task_download_txt_4 = SSHOperator(
        task_id='task_download_txt_4',
        ssh_conn_id="ssh_08",
        command=bash_download_txt,
        dag=dag
    )

    task_merge_txt_4 = SSHOperator(
        task_id='task_merge_txt_4',
        ssh_conn_id="ssh_08",
        command=bash_merge_txt,
        dag=dag
    )

    clear_YaApi_query_4 = PythonOperator(
        task_id='clear_YaApi_query_4',
        python_callable=clear_YaApi_query,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_move_bigTxt_4 = SSHOperator(
        task_id='task_move_bigTxt_4',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_Device_orc = SSHOperator(
        task_id='task_start_pySpark_Device_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_Device_orc,
        dag=dag
    )

    task_clear_tmp_5 = SSHOperator(
        task_id='task_clear_tmp_5',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_5 = SSHOperator(
        task_id='task_clear_hdfs_5',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    task_start_pySpark_join = SSHOperator(
        task_id='task_start_pySpark_join',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_join,
        dag=dag
    )

    task_rm_4dir_hdfs_2 = SSHOperator(
        task_id='task_rm_4dir_hdfs_2',
        ssh_conn_id="ssh_08",
        command=bash_rm_4dir_hdfs,
        dag=dag
    )

    tlgrm_allSuccess = PythonOperator(
        task_id='tlgrm_allSuccess',
        python_callable=tlgrm,
        dag=dag,
        trigger_rule='all_success',
        op_kwargs={
            'message': f"–û—Ç—Ä–∞–±–æ—Ç–∞–ª —É—Å–ø–µ—à–Ω–æ ‚úÖ - DAG hits_selectDate_{start_date_v}_{end_date_v}"}
    )

    tlgrm_oneFailed = PythonOperator(
        task_id='tlgrm_oneFailed',
        python_callable=tlgrm,
        dag=dag,
        trigger_rule='one_failed',
        op_kwargs={
            'message': f"–£–ø–∞–ª üõë - DAG hits_selectDate_{request_id_v}_{start_date_v}_{end_date_v}"}
    )

    logging_faild = PythonOperator(
        task_id='logging_faild',
        python_callable=logging_faild,
        dag=dag,
        trigger_rule='one_failed',
        op_kwargs={
            'text': f"DAG hits_selectDate_{request_id_v}_{start_date_v}_{end_date_v} - faild" + "\n",
            'path_faild': path_faild_v}
    )

(task_clear_tmp_1 >> task_clear_hdfs_1 >> task_rm_4dir_hdfs_1 >> ocenka_vozmozhnisti_sozd_zaprosa_1 >> sozd_zaprosa_logov_1 >> get_status_1 >> task_save_request_id_1 >> task_extract_partsize_1 >> task_download_txt_1 >> task_merge_txt_1 >> clear_YaApi_query_1 >> task_move_bigTxt_1 >> task_start_pySpark_Basic_orc >> task_clear_tmp_2 >> task_clear_hdfs_2 >> ocenka_vozmozhnisti_sozd_zaprosa_2 >> sozd_zaprosa_logov_2 >> get_status_2 >> task_save_request_id_2 >> task_extract_partsize_2 >> task_download_txt_2 >> task_merge_txt_2 >> clear_YaApi_query_2 >> task_move_bigTxt_2 >> task_start_pySpark_TrafficSource_orc >> task_clear_tmp_3 >> task_clear_hdfs_3 >> ocenka_vozmozhnisti_sozd_zaprosa_3 >> sozd_zaprosa_logov_3 >> get_status_3 >> task_save_request_id_3 >> task_extract_partsize_3 >> task_download_txt_3 >> task_merge_txt_3 >> clear_YaApi_query_3 >> task_move_bigTxt_3 >> task_start_pySpark_3E_orc >> task_clear_tmp_4 >> task_clear_hdfs_4 >> ocenka_vozmozhnisti_sozd_zaprosa_4 >> sozd_zaprosa_logov_4 >> get_status_4 >> task_save_request_id_4 >> task_extract_partsize_4 >> task_download_txt_4 >> task_merge_txt_4 >> clear_YaApi_query_4 >> task_move_bigTxt_4 >> task_start_pySpark_Device_orc >> task_clear_tmp_5 >> task_clear_hdfs_5 >> task_start_pySpark_join >> task_rm_4dir_hdfs_2 >> [tlgrm_allSuccess, tlgrm_oneFailed, logging_faild])
