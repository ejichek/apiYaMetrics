import os
import sys
import json
import requests
from datetime import datetime, date, timedelta

from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.sensors.python import PythonSensor
from airflow.operators.python_operator import PythonOperator
from airflow.contrib.operators.ssh_operator import SSHOperator

# ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð³ÑƒÑ‚ ÑÐ¾ Ð²Ñ€ÐµÐ¼ÐµÐ½ÐµÐ¼ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑÑ
with open('/tmp/zhalybin/yaApi_logs/json_hits_constant.json', 'r', encoding="utf-8") as jsonFile1:
    constantJsonData = json.load(jsonFile1)

# Ð”Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ñ‡Ð½Ð¾Ð¹ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð² json,
# Ñ‡Ñ‚Ð¾Ð± Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ñ„Ð°Ð¹Ð» Ð½Ð° Ñ…Ð¾ÑÑ‚Ðµ Ð° Ð½Ðµ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¸ 
with open('/tmp/zhalybin/yaApi_logs/json_hits_select_date.json', 'r', encoding="utf-8") as jsonFile2:
    selectDateJsonData = json.load(jsonFile2)

# Ð”Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ñ‡Ð½Ð¾Ð¹ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸
start_date_v = selectDateJsonData['YaApiHitsDate']['startDate']
end_date_v = selectDateJsonData['YaApiHitsDate']['endDate']

# ÐŸÑ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ 
col_tab_Basic = constantJsonData['YaApiHitsConstant']['col_tab_Basic']
col_tab_TrafficSource = constantJsonData['YaApiHitsConstant']['col_tab_TrafficSource']
col_tab_Ecommerce_EventParams_EventType = constantJsonData['YaApiHitsConstant']['col_tab_Ecommerce_EventParams_EventType']
col_tab_Device = constantJsonData['YaApiHitsConstant']['col_tab_Device']

counter_id_v = constantJsonData['YaApiHitsConstant']['counter_id']
API_token_v = constantJsonData['YaApiHitsConstant']['API_token']
headers_v = {'Authorization': f"OAuth {API_token_v}", 'Accept-Encoding': 'gzip'}

# BASH ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ‚Ð¾Ð»ÐºÐ°ÑŽÑ‚ ÑÐºÑ€Ð¸Ð¿Ñ‚Ñ‹ Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ 08 Ñ…Ð¾ÑÑ‚Ð°  
bash_clear_tmp = '/usr/bin/python3 /home/bdataadmin/airflow/test_script/clear_logs_folder.py'
bash_clear_hdfs = '/usr/bin/bash /home/bdataadmin/airflow/test_script/Ñheck_hdfs_txt.sh '

bash_rm_4dir_hdfs = '/usr/bin/bash /home/bdataadmin/airflow/test_script/remove_4dir_hdfs.sh '

bash_command_extract_partsize = '/usr/bin/python3 /home/bdataadmin/airflow/test_script/extract_partsize.py'
bash_download_txt = '/usr/bin/python3 /home/bdataadmin/airflow/test_script/dowload_parts.py'
bash_merge_txt = '/usr/bin/python3 /home/bdataadmin/airflow/test_script/merge_txt.py'
bash_hdfs_put_bigTxt = '/usr/bin/bash hdfs dfs -put /home/bdataadmin/airflow/txt_big/final_txt.txt /user/azhalybin/airflow/test/txt '

bash_start_pySpark_basic_orc = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_basic_orc.sh '
bash_start_pySpark_trafficSource_orc = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_trafficSource_orc.sh '
bash_start_pySpark_3E_orc = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_3E_orc.sh '
bash_start_pySpark_Device_orc = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_device_orc.sh '
bash_start_pySpark_join = '/usr/bin/bash /home/bdataadmin/airflow/test_script/start_pySpark_hits_join.sh '

# ÐŸÐ¾ÑÑ‚Ð¾ÑÐ½Ð½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸ Ð´Ð»Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ñ… Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ DAG-Ð°
# Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ airflow Ñ…ÑÑ‚Ð°  
path_request_id_v = '/tmp/zhalybin/yaApi_logs/request_id.txt'
path_faild_v = '/tmp/zhalybin/yaApi_logs/hits_faild.txt'


def read_request_id(path_request_id):
    """
    Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð½ÑƒÐ¶Ð½Ð° Ñ‡Ñ‚Ð¾Ð± Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ð¹ request_id,
    Ð¾Ð½Ð° Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð² Ñ„Ð°Ð¹Ð»Ðµ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ÑÑ
    """
    with open(path_request_id, "r") as f:
        request_id = f.read()
    return request_id

# Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²ÐµÐ¼ Ð² Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð¸Ð½Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
# Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð° Ð½Ð° Ñ…Ð¾ÑÑ‚Ðµ airflow - Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð³Ñƒ Ð¸ xcom Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚
request_id_v = read_request_id(path_request_id=path_request_id_v)
# Ð”ÑƒÐ±Ð»Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð½Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð½Ð° 08 Ñ…Ð¾ÑÑ‚Ðµ
bash_command_request_id = f'echo "{request_id_v}" > /home/bdataadmin/airflow/logs/request_id.txt'


def ocenka_vozmozhnisti_sozd_zaprosa(counter_id, API_token, headers, start_date, end_date, col_tab):
    """
    ÐžÑ†ÐµÐ½ÐºÐ° Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ Ð¯Ðœ,
    Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ ÑˆÐ»ÐµÑ‚ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑ‚
    Ð¸ Ð¼Ñ‹ Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ r.json()['log_request_evaluation']['possible'] == True
    """
    get_ocenka = f"https://api-metrika.yandex.net/management/v1/counter/{counter_id}/logrequests/evaluate"

    params_ocenka = {
        'date1': start_date,
        'date2': end_date,
        'fields': col_tab,
        'source': 'hits'  # hits visits
    }

    r = requests.get(get_ocenka, params=params_ocenka, headers=headers)

    if r.status_code == 200:
        if r.json()['log_request_evaluation']['possible'] == True:
            print('Ð’Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ° Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð°')
        elif r.json()['log_request_evaluation']['possible'] == False:
            print('YaApi Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð» Ñ‡Ñ‚Ð¾ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ° Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð° ' + str(r.status_code))
            return False
        else:
            print('Ð§Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº' + str(r.status_code))
            return False
    else:
        sys.exit('Ð—Ð°Ð¿Ñ€Ð¾Ñ ÑƒÐ¿Ð°Ð»: ' + str(r.status_code))
        return False


def sozd_zaprosa_logov(counter_id, API_token, headers, start_date, end_date, col_tab, path_request_id):
    """
    Ð˜ÑÑ…Ð¾Ð´Ñ Ð¸Ð· Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
    Ð¼Ñ‹ Ð¾Ñ‚Ð¿Ñ€Ð¿Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½Ð° Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸. 
    ÐŸÐ¾Ñ…Ð¾Ð¶Ð¸Ð¹ ÑÐºÑ€Ð¸Ð¿Ñ‚ Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ 08 Ñ…Ð¾ÑÑ‚Ð° ÑÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÑ‚ Ð¸
    Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð² Ñ„Ð°Ð¹Ð» Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€ Ð·Ð½Ñ‡ÐµÐ½Ð¸Ð¹:
    Ð½Ð¾Ð¼ÐµÑ€ Ñ‡Ð°ÑÑ‚Ð¸ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ (parts) Ð¸ Ñ€Ð°Ð·Ð¼ÐµÑ€ ÑÑ‚Ð¾Ð¹ Ñ‡Ð°ÑÑ‚Ð¸ (partSizes) 
    """
    post_sozdanie_zaprosa_logov = f"https://api-metrika.yandex.net/management/v1/counter/{counter_id}/logrequests"

    params_sozdanie_zaprosa_logov = {
        'date1': start_date,
        'date2': end_date,
        'fields': col_tab,
        'source': 'hits'  # hits visits
    }

    r = requests.post(post_sozdanie_zaprosa_logov, params=params_sozdanie_zaprosa_logov, headers=headers)

    if os.path.exists(path_request_id) == True:
        os.remove(path_request_id)

    if r.status_code == 200:
        if r.json()['log_request']['status'] == 'created':
            print('Ð—Ð°Ð¿Ñ€Ð¾Ñ ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ÑÑ')
            # print(r.json()['log_request']['request_id'])
            with open(path_request_id, 'w', encoding='utf-8') as f:
                f.write(str(r.json()['log_request']['request_id']))
        else:
            sys.exit('Ð§Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº' + str(r.status_code))
            return False
    else:
        sys.exit('Ð—Ð°Ð¿Ñ€Ð¾Ñ ÑƒÐ¿Ð°Ð»: ' + str(r.status_code))
        return False


def get_status(counter_id, API_token, headers, request_id):
    """
    ÐŸÐ¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ Ð¯Ðœ, ÑÐ°Ð¼Ð¾Ð¼Ñƒ Ð¯Ðœ 
    Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð²Ñ€ÐµÐ¼Ñ Ð½Ð° Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸
    Ð¸ ÑÑ‚Ð° Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ‚Ð¾Ð¼
    Ð³Ð¾Ñ‚Ð¾Ð² Ð»Ð¸ Ðº Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐµ Ð½Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ
    """

    get_status = f"https://api-metrika.yandex.net/management/v1/counter/{counter_id}/logrequest/{request_id}"

    r = requests.get(get_status, headers=headers)

    if r.status_code == 200:
        if r.json()['log_request']['status'] == 'processed':
            print('Ð£ÑÐ¿ÐµÑ…')
            return True
        elif r.json()['log_request']['status'] == 'created':
            print('ÐÑƒÐ¶Ð½Ð¾ Ð¶Ð´Ð°Ñ‚ÑŒ, Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð² ÑÑ‚Ð°Ñ‚ÑƒÑÐµ created Ð¸ ÑƒÐ¶Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ‚ÑÑ Ð¸Ð»Ð¸ Ð² Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸ Ð½Ð° Ð¸ÑÐ¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ')
            return False
        else:
            sys.exit('Ð§Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº' + str(r.status_code))
            return False
    else:
        sys.exit('Ð—Ð°Ð¿Ñ€Ð¾Ñ ÑƒÐ¿Ð°Ð»: ' + str(r.status_code))
        return False


def clear_YaApi_query(counter_id, API_token, headers, request_id):
    """
    ÐŸÐ¾ÑÐ»Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð¹ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð²ÑÐµÑ… Ñ‡Ð°ÑÑ‚ÐµÐ¹ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° 
    Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¸Ñ… Ð½Ð° Ð¿Ð¾Ð»Ð½Ð¾Ñ‚Ñƒ (Ð½Ð° ÑÑ‚Ñ€Ð¾Ð½Ðµ 08 Ñ…Ð¾ÑÑ‚Ð°)
    Ð¼Ñ‹ Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð½Ð°ÑˆÐµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ (Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¼ 10 Ð“Ð±
    Ð² Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸) Ð´Ð»Ñ Ð¿Ð¾ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ñ… Ð²Ñ‹Ð³Ñ€ÑƒÐ·Ð¾Ðº   
    """
    post_clean = f"https://api-metrika.yandex.net/management/v1/counter/{counter_id}/logrequest/{request_id}/clean"
    r = requests.post(post_clean, headers=headers)
    if r.status_code == 200:
        if r.json()['log_request']['status'] == 'cleaned_by_user':
            print('Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð¯Ð½Ð´ÐµÐºÑ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ñ‹ Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ Ð¯Ð½Ð´ÐµÐºÑÐ°')
        else:
            sys.exit('Ð§Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº' + str(r.status_code))
            return False
    else:
        sys.exit('Ð—Ð°Ð¿Ñ€Ð¾Ñ ÑƒÐ¿Ð°Ð»: ' + str(r.status_code))
        return False


# DAG ÑƒÐ¿Ð°Ð» ðŸ›‘
# DAG Ð¾Ñ‚Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ âœ…
def tlgrm(message):
    """
    Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼Ð¼ Ð±Ð¾Ñ‚ ÑˆÐ»ÐµÑ‚ Ð² Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼Ð¼ Ð±ÐµÑÐµÐ´Ñƒ
    Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ Ð¾Ð± ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ Ð½Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ DAG-Ð°.
    Ð‘ÐµÑÐµÐ´Ð° Ð½Ð°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ: AFLT_BigDataReports
    """
    token = "7437864886:AAGbHErZlCVqycGfYhkrB14iYevybpqErjc"
    url = "https://api.telegram.org/bot"
    channel_id = "-1002335777312"
    url += token
    method = url + "/sendMessage"
    #    proxy = {'https': '192.168.41.118:1080'}
    #    proxy = {'https': 'http://192.168.41.118:1080'}

    try:
        r = requests.post(method,
                          data={
                              "chat_id": channel_id,
                              "text": message},
                          #                          proxies=proxy,
                          timeout=30)
        print(r.json())
    except requests.exceptions.ConnectionError:
        print("Ð˜ÑÐºÐ»_1")
        return False


def logging_faild(text, path_faild):
    """
    Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð² Ñ„Ð°Ð¹Ð» Ñ„Ð°ÐºÑ‚ Ð½ÐµÑƒÑÐ¿ÐµÑ…Ð°
    Ð¸ Ð¸Ð½Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
    Ð´Ð»Ñ Ñ‡Ñ‚Ð¾Ð± Ð¾Ñ‡Ð¸Ñ‚Ð¸Ñ‚ÑŒ ÐµÐ³Ð¾ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ, ÐµÑÐ»Ð¸ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ
    """
    with open(path_faild, 'a', encoding='utf-8') as f:
        f.write(text + '\n')


default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 8, 25),
    'retries': 0
}

# Ð’ DAG-Ðµ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð° Ð»Ð¾Ð³Ð¸ÐºÐ° Ð¿Ñ€Ð¸ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´ÐµÐ»Ð¸Ñ‚ÑÑ Ð½Ð° 4 Ñ‡Ð°ÑÑ‚Ð¸
# Ð¸ join-Ñ‚ÑÑ Ð½Ð° Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¼ ÑÑ‚Ð°Ð¿Ðµ Ñ Ð¾Ñ‚Ñ€Ð°Ð²ÐºÐ¾Ð¹ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼ Ñ€ÐµÐ¿Ð¾Ñ€Ñ‚ÐµÑ€.
# Ð•ÑÐ»Ð¸ Ð½Ð° ÐºÐ°ÐºÐ¾Ð¼-Ñ‚Ð¾ ÑƒÐ·Ð»Ðµ DAG-Ð° Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº - ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ñ‡Ñ‚Ð¾ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ° Ð½ÐµÑƒÑÐ¿ÐµÑˆÐ½Ð°
# Ð¸ Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ð¾Ð¹ Ð´Ð°Ñ‚Ñ‹ Ð½ÑƒÐ¶Ð½Ð¾ Ð½Ð°Ñ‡Ð¸Ð½Ð°Ñ‚ÑŒ Ð²ÑÐµ ÑÐ½Ð°Ñ‡Ð°Ð»Ð°. 
# Ð”Ð»Ñ Ð²Ð¸Ð·Ð¸Ñ‚Ð¾Ð² Ð¸ Ñ…Ð¸Ñ‚Ð¾Ð² ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‚ Ð¿Ð°Ñ€Ñ‹ DAG-Ð¾Ð²: 1)Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ð¼ Ð´Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸
# 2) Ð¸ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð¼ Ð½Ð° Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ - ÐºÐ¾Ñ‚Ñ€Ñ€Ñ‹Ð¹ Ð»ÑƒÑ‡ÑˆÐµ Ð½Ðµ Ñ‚Ñ€Ð¾Ð³Ð°Ñ‚ÑŒ.
with DAG(dag_id='BigData_YaApi_hits_date_selection',
         tags=["ETL Ð´Ð»Ñ Ñ€Ð°Ð·Ð¾Ð²Ñ‹Ñ… Ð²Ñ‹Ð³Ñ€ÑƒÐ·Ð¾Ðº"],
         default_args=default_args,
         schedule_interval='@once',
         start_date=days_ago(1)
         ) as dag:

    task_clear_tmp_1 = SSHOperator(
        task_id='task_clear_tmp_1',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_1 = SSHOperator(
        task_id='task_clear_hdfs_1',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    task_rm_4dir_hdfs_1 = SSHOperator(
        task_id='task_rm_4dir_hdfs_1',
        ssh_conn_id="ssh_08",
        command=bash_rm_4dir_hdfs,
        dag=dag
    )

    ocenka_vozmozhnisti_sozd_zaprosa_1 = PythonOperator(
        task_id='ocenka_vozmozhnisti_sozd_zaprosa_1',
        python_callable=ocenka_vozmozhnisti_sozd_zaprosa,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Basic}
    )

    sozd_zaprosa_logov_1 = PythonOperator(
        task_id='sozd_zaprosa_logov_1',
        python_callable=sozd_zaprosa_logov,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Basic,
            'path_request_id': path_request_id_v}
    )

    get_status_1 = PythonSensor(
        task_id='get_status_1',
        python_callable=get_status,
        poke_interval=5 * 60,  # ÐºÐ°Ð¶Ð´Ñ‹Ðµ 5 Ð¼Ð¸Ð½ÑƒÑ‚, Ð§ÐµÑ€ÐµÐ· ÐºÐ°ÐºÐ¾Ðµ Ð²Ñ€ÐµÐ¼Ñ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒÑÑ (5 * 60)
        timeout=12 * 60 * 60,  # Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ, 12 Ñ‡Ð°ÑÐ¾Ð²
        # retries=720,
        soft_fail=False,
        mode="reschedule",
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_save_request_id_1 = SSHOperator(
        task_id='task_save_request_id_1',
        ssh_conn_id="ssh_08",
        command=bash_command_request_id,
        dag=dag
    )

    task_extract_partsize_1 = SSHOperator(
        task_id='task_extract_partsize_1',
        ssh_conn_id="ssh_08",
        command=bash_command_extract_partsize,
        dag=dag
    )

    task_download_txt_1 = SSHOperator(
        task_id='task_download_txt_1',
        ssh_conn_id="ssh_08",
        command=bash_download_txt,
        dag=dag
    )

    task_merge_txt_1 = SSHOperator(
        task_id='task_merge_txt_1',
        ssh_conn_id="ssh_08",
        command=bash_merge_txt,
        dag=dag
    )

    clear_YaApi_query_1 = PythonOperator(
        task_id='clear_YaApi_query_1',
        python_callable=clear_YaApi_query,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_move_bigTxt_1 = SSHOperator(
        task_id='task_move_bigTxt_1',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_Basic_orc = SSHOperator(
        task_id='task_start_pySpark_Basic_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_basic_orc,
        dag=dag
    )

    task_clear_tmp_2 = SSHOperator(
        task_id='task_clear_tmp_2',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_2 = SSHOperator(
        task_id='task_clear_hdfs_2',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    ocenka_vozmozhnisti_sozd_zaprosa_2 = PythonOperator(
        task_id='ocenka_vozmozhnisti_sozd_zaprosa_2',
        python_callable=ocenka_vozmozhnisti_sozd_zaprosa,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_TrafficSource}
    )

    sozd_zaprosa_logov_2 = PythonOperator(
        task_id='sozd_zaprosa_logov_2',
        python_callable=sozd_zaprosa_logov,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_TrafficSource,
            'path_request_id': path_request_id_v}
    )

    get_status_2 = PythonSensor(
        task_id='get_status_2',
        python_callable=get_status,
        poke_interval=5 * 60,  # ÐºÐ°Ð¶Ð´Ñ‹Ðµ 5 Ð¼Ð¸Ð½ÑƒÑ‚, Ð§ÐµÑ€ÐµÐ· ÐºÐ°ÐºÐ¾Ðµ Ð²Ñ€ÐµÐ¼Ñ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒÑÑ (5 * 60)
        timeout=12 * 60 * 60,  # Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ, 12 Ñ‡Ð°ÑÐ¾Ð²
        # retries=720,
        soft_fail=False,
        mode="reschedule",
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_save_request_id_2 = SSHOperator(
        task_id='task_save_request_id_2',
        ssh_conn_id="ssh_08",
        command=bash_command_request_id,
        dag=dag
    )

    task_extract_partsize_2 = SSHOperator(
        task_id='task_extract_partsize_2',
        ssh_conn_id="ssh_08",
        command=bash_command_extract_partsize,
        dag=dag
    )

    task_download_txt_2 = SSHOperator(
        task_id='task_download_txt_2',
        ssh_conn_id="ssh_08",
        command=bash_download_txt,
        dag=dag
    )

    task_merge_txt_2 = SSHOperator(
        task_id='task_merge_txt_2',
        ssh_conn_id="ssh_08",
        command=bash_merge_txt,
        dag=dag
    )

    clear_YaApi_query_2 = PythonOperator(
        task_id='clear_YaApi_query_2',
        python_callable=clear_YaApi_query,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_move_bigTxt_2 = SSHOperator(
        task_id='task_move_bigTxt_2',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_TrafficSource_orc = SSHOperator(
        task_id='task_start_pySpark_TrafficSource_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_trafficSource_orc,
        dag=dag
    )

    task_clear_tmp_3 = SSHOperator(
        task_id='task_clear_tmp_3',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_3 = SSHOperator(
        task_id='task_clear_hdfs_3',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    ocenka_vozmozhnisti_sozd_zaprosa_3 = PythonOperator(
        task_id='ocenka_vozmozhnisti_sozd_zaprosa_3',
        python_callable=ocenka_vozmozhnisti_sozd_zaprosa,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Ecommerce_EventParams_EventType}
    )

    sozd_zaprosa_logov_3 = PythonOperator(
        task_id='sozd_zaprosa_logov_3',
        python_callable=sozd_zaprosa_logov,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Ecommerce_EventParams_EventType,
            'path_request_id': path_request_id_v}
    )

    get_status_3 = PythonSensor(
        task_id='get_status_3',
        python_callable=get_status,
        poke_interval=5 * 60,  # ÐºÐ°Ð¶Ð´Ñ‹Ðµ 5 Ð¼Ð¸Ð½ÑƒÑ‚, Ð§ÐµÑ€ÐµÐ· ÐºÐ°ÐºÐ¾Ðµ Ð²Ñ€ÐµÐ¼Ñ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒÑÑ (5 * 60)
        timeout=12 * 60 * 60,  # Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ, 12 Ñ‡Ð°ÑÐ¾Ð²
        # retries=720,
        soft_fail=False,
        mode="reschedule",
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_save_request_id_3 = SSHOperator(
        task_id='task_save_request_id_3',
        ssh_conn_id="ssh_08",
        command=bash_command_request_id,
        dag=dag
    )

    task_extract_partsize_3 = SSHOperator(
        task_id='task_extract_partsize_3',
        ssh_conn_id="ssh_08",
        command=bash_command_extract_partsize,
        dag=dag
    )

    task_download_txt_3 = SSHOperator(
        task_id='task_download_txt_3',
        ssh_conn_id="ssh_08",
        command=bash_download_txt,
        dag=dag
    )

    task_merge_txt_3 = SSHOperator(
        task_id='task_merge_txt_3',
        ssh_conn_id="ssh_08",
        command=bash_merge_txt,
        dag=dag
    )

    clear_YaApi_query_3 = PythonOperator(
        task_id='clear_YaApi_query_3',
        python_callable=clear_YaApi_query,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_move_bigTxt_3 = SSHOperator(
        task_id='task_move_bigTxt_3',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_3E_orc = SSHOperator(
        task_id='task_start_pySpark_3E_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_3E_orc,
        dag=dag
    )

    task_clear_tmp_4 = SSHOperator(
        task_id='task_clear_tmp_4',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_4 = SSHOperator(
        task_id='task_clear_hdfs_4',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    ocenka_vozmozhnisti_sozd_zaprosa_4 = PythonOperator(
        task_id='ocenka_vozmozhnisti_sozd_zaprosa_4',
        python_callable=ocenka_vozmozhnisti_sozd_zaprosa,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Device}
    )

    sozd_zaprosa_logov_4 = PythonOperator(
        task_id='sozd_zaprosa_logov_4',
        python_callable=sozd_zaprosa_logov,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'start_date': start_date_v,
            'end_date': end_date_v,
            'col_tab': col_tab_Device,
            'path_request_id': path_request_id_v}
    )

    get_status_4 = PythonSensor(
        task_id='get_status_4',
        python_callable=get_status,
        poke_interval=5 * 60,  # ÐºÐ°Ð¶Ð´Ñ‹Ðµ 5 Ð¼Ð¸Ð½ÑƒÑ‚, Ð§ÐµÑ€ÐµÐ· ÐºÐ°ÐºÐ¾Ðµ Ð²Ñ€ÐµÐ¼Ñ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒÑÑ (5 * 60)
        timeout=12 * 60 * 60,  # Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ, 12 Ñ‡Ð°ÑÐ¾Ð²
        # retries=720,
        soft_fail=False,
        mode="reschedule",
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_save_request_id_4 = SSHOperator(
        task_id='task_save_request_id_4',
        ssh_conn_id="ssh_08",
        command=bash_command_request_id,
        dag=dag
    )

    task_extract_partsize_4 = SSHOperator(
        task_id='task_extract_partsize_4',
        ssh_conn_id="ssh_08",
        command=bash_command_extract_partsize,
        dag=dag
    )

    task_download_txt_4 = SSHOperator(
        task_id='task_download_txt_4',
        ssh_conn_id="ssh_08",
        command=bash_download_txt,
        dag=dag
    )

    task_merge_txt_4 = SSHOperator(
        task_id='task_merge_txt_4',
        ssh_conn_id="ssh_08",
        command=bash_merge_txt,
        dag=dag
    )

    clear_YaApi_query_4 = PythonOperator(
        task_id='clear_YaApi_query_4',
        python_callable=clear_YaApi_query,
        dag=dag,
        op_kwargs={
            'counter_id': counter_id_v,
            'API_token': API_token_v,
            'headers': headers_v,
            'request_id': read_request_id(path_request_id=path_request_id_v)}
    )

    task_move_bigTxt_4 = SSHOperator(
        task_id='task_move_bigTxt_4',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_Device_orc = SSHOperator(
        task_id='task_start_pySpark_Device_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_Device_orc,
        dag=dag
    )

    task_clear_tmp_5 = SSHOperator(
        task_id='task_clear_tmp_5',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_5 = SSHOperator(
        task_id='task_clear_hdfs_5',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    task_start_pySpark_join = SSHOperator(
        task_id='task_start_pySpark_join',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_join,
        dag=dag
    )

    task_rm_4dir_hdfs_2 = SSHOperator(
        task_id='task_rm_4dir_hdfs_2',
        ssh_conn_id="ssh_08",
        command=bash_rm_4dir_hdfs,
        dag=dag
    )

    tlgrm_allSuccess = PythonOperator(
        task_id='tlgrm_allSuccess',
        python_callable=tlgrm,
        dag=dag,
        trigger_rule='all_success',
        op_kwargs={
            'message': f"ÐžÑ‚Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ âœ… - DAG hits_selectDate_{start_date_v}_{end_date_v}"}
    )

    tlgrm_oneFailed = PythonOperator(
        task_id='tlgrm_oneFailed',
        python_callable=tlgrm,
        dag=dag,
        trigger_rule='one_failed',
        op_kwargs={
            'message': f"Ð£Ð¿Ð°Ð» ðŸ›‘ - DAG hits_selectDate_{request_id_v}_{start_date_v}_{end_date_v}"}
    )

    logging_faild = PythonOperator(
        task_id='logging_faild',
        python_callable=logging_faild,
        dag=dag,
        trigger_rule='one_failed',
        op_kwargs={
            'text': f"DAG hits_selectDate_{request_id_v}_{start_date_v}_{end_date_v} - faild" + "\n",
            'path_faild': path_faild_v}
    )

(task_clear_tmp_1 >> task_clear_hdfs_1 >> task_rm_4dir_hdfs_1 >> ocenka_vozmozhnisti_sozd_zaprosa_1 >> sozd_zaprosa_logov_1 >> get_status_1 >> task_save_request_id_1 >> task_extract_partsize_1 >> task_download_txt_1 >> task_merge_txt_1 >> clear_YaApi_query_1 >> task_move_bigTxt_1 >> task_start_pySpark_Basic_orc >> task_clear_tmp_2 >> task_clear_hdfs_2 >> ocenka_vozmozhnisti_sozd_zaprosa_2 >> sozd_zaprosa_logov_2 >> get_status_2 >> task_save_request_id_2 >> task_extract_partsize_2 >> task_download_txt_2 >> task_merge_txt_2 >> clear_YaApi_query_2 >> task_move_bigTxt_2 >> task_start_pySpark_TrafficSource_orc >> task_clear_tmp_3 >> task_clear_hdfs_3 >> ocenka_vozmozhnisti_sozd_zaprosa_3 >> sozd_zaprosa_logov_3 >> get_status_3 >> task_save_request_id_3 >> task_extract_partsize_3 >> task_download_txt_3 >> task_merge_txt_3 >> clear_YaApi_query_3 >> task_move_bigTxt_3 >> task_start_pySpark_3E_orc >> task_clear_tmp_4 >> task_clear_hdfs_4 >> ocenka_vozmozhnisti_sozd_zaprosa_4 >> sozd_zaprosa_logov_4 >> get_status_4 >> task_save_request_id_4 >> task_extract_partsize_4 >> task_download_txt_4 >> task_merge_txt_4 >> clear_YaApi_query_4 >> task_move_bigTxt_4 >> task_start_pySpark_Device_orc >> task_clear_tmp_5 >> task_clear_hdfs_5 >> task_start_pySpark_join >> task_rm_4dir_hdfs_2 >> [tlgrm_allSuccess, tlgrm_oneFailed, logging_faild])
